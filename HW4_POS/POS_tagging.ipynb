{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this homework you will\n",
    "- Implemtn Viterbi Search algorithm\n",
    "- MEMM model to tag tokens in the corpus\n",
    "- A [reference](https://www.aclweb.org/anthology/W96-0213) for MEMM feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T05:16:56.542579Z",
     "start_time": "2019-04-03T05:16:56.495628Z"
    }
   },
   "outputs": [],
   "source": [
    "from tools import check_path_search, load_data, save_prediction\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import sparse\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tags` is a dictionary that maps the [Treebank tag](https://www.clips.uantwerpen.be/pages/mbsp-tags) to its numerical encoding. There are 45 tags in total, plus a special tag `START (tags[-1])` to indicate the beginning of a sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T05:10:05.453780Z",
     "start_time": "2019-04-03T05:10:04.295178Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 33539\n",
      "Dev set: 11180\n",
      "Testing set: 9955\n"
     ]
    }
   ],
   "source": [
    "tags = pd.read_csv('tags.csv', index_col=0).tag_encode.to_dict()\n",
    "\n",
    "train, train_label = load_data(\"train.txt\")\n",
    "train, dev, train_label, dev_label = train_test_split(train, train_label)\n",
    "test, _ = load_data(\"test.txt\")\n",
    "\n",
    "print(\"Training set: %d\" % len(train))\n",
    "print(\"Dev set: %d\" % len(dev))\n",
    "print(\"Testing set: %d\" % len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shortest Path Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the class we introduced the first order markov model (HMM and MEMM). In these models, the probability distribution of the current state at `t` is conditioned on the previous state at `t-1`. \n",
    "\n",
    "Suppose:\n",
    "- `L` is the number of tags\n",
    "- `T` is the length of the sentence\n",
    "- $g_t$ is the predicted tag at time t \n",
    "\n",
    "The probability of the current stage can be discribed by a `(L+1)*L` matrix (taking into account of the extra `START` tag). The model output for a given sentence should be a `T*(L+1)*L` matrix (`Ms`) where:\n",
    "\\begin{equation*}\n",
    "    Ms[t, i, j] = p(g_t==j|g_{t-1}==i)\n",
    "\\end{equation*}   \n",
    "\n",
    "However, we need a post processing to convert the model output into the final prediction. The idea is to find such a path $\\{g_0, g_1, g_2, ..., g_T\\}$ so that the path probability is maximized:\n",
    "\n",
    "\\begin{equation*}\n",
    "    P(g_0, g_1, ..., g_T) = \\Pi_{t=1}^n p(g_t|g_{t-1})\n",
    "\\end{equation*}\n",
    "\n",
    "In practice, you may find that $\\Pi_{t=1}^n p(g_t|g_{t-1})$ diminish to zero very quickly. For numerical stability, we maximize the logarithm of the path probability:\n",
    "\\begin{equation*}\n",
    "    lg(P(g_0, g_1, ..., g_T)) = \\sum_{t=1}^n lg(p(g_t|g_{t-1}))\n",
    "\\end{equation*}\n",
    "\n",
    "## Greedy method\n",
    "Heuristically one can use greedy path search, meaning to greedily choose the step that maximize the current probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T04:12:13.509676Z",
     "start_time": "2019-04-03T04:12:13.478794Z"
    }
   },
   "outputs": [],
   "source": [
    "def greedy_path_search(Ms):\n",
    "    \"\"\" \n",
    "    greedy path search to get the label prediction path\n",
    "    \n",
    "    input: np.array(T, L+1, L)\n",
    "    return: list, prediction path\n",
    "    \"\"\"\n",
    "    path = [tags['START']]\n",
    "    for t, M in enumerate(Ms):\n",
    "        gt = np.argmax(M[path[-1]])\n",
    "        path.append(gt)\n",
    "    return path[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " here we load some test data, and see what is the output of this `greedy_path_search`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T04:12:14.955414Z",
     "start_time": "2019-04-03T04:12:14.751960Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"examples.pickle\",\"rb\") as f:\n",
    "    examples = pickle.load(f)\n",
    "    \n",
    "print(\"example 0: \", greedy_path_search(examples[0]['Ms']))\n",
    "print(\"example 1: \", greedy_path_search(examples[1]['Ms']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viterbi path search \n",
    "\n",
    "There is no guarrantee that the greedy search can always find the optimal solution. You can run the test below and see that for most of the time, the greedy search leads to the wrong result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T04:12:32.499494Z",
     "start_time": "2019-04-03T04:12:32.435593Z"
    }
   },
   "outputs": [],
   "source": [
    "check_path_search(greedy_path_search, examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We introduce the [viterbi algorithm](https://en.wikipedia.org/wiki/Viterbi_algorithm). Instead of choosing the maximum probability at the current step, we use DP (dynamical programming) to memorize the best paths to all the possible tags at time `t` and the corresponding probability. This algorithm has been explained in details in class. Refer to your notes if you are in doubts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T03:47:48.855459Z",
     "start_time": "2019-04-03T03:47:48.821757Z"
    }
   },
   "outputs": [],
   "source": [
    "def viterbi_path_search(Ms):\n",
    "    \"\"\"\n",
    "        :param\n",
    "        Ms: np.array(T, L+1, L)\n",
    "        return: list, prediction path\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "        Write your code below\n",
    "\n",
    "        Hints:\n",
    "        1. You need a matrix to store the current path probabilities\n",
    "        2. You need a matrix to store the backpointers to retrieve \n",
    "        the path\n",
    "        3. Remember that the path probability diminish to zero fast, what\n",
    "        should you do for numerical stability?\n",
    "    \"\"\"\n",
    "   \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T07:02:39.245845Z",
     "start_time": "2019-04-02T07:02:37.351095Z"
    }
   },
   "outputs": [],
   "source": [
    "check_path_search(viterbi_path_search, examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEMM (1st order) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training clas we use here is a little similar to the one we have in HW01. I provide the code for you so you can focus on the important part of the model, `featurization`. First go through the code and understand how it works. It helps you to accomplish the work after."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T05:14:20.197334Z",
     "start_time": "2019-04-03T05:14:20.146236Z"
    }
   },
   "outputs": [],
   "source": [
    "class BaseFeaturizer:\n",
    "    \"\"\"\n",
    "    A template for the Featurizer. Later you will have to create your own featurizer, it has to follow\n",
    "    the class signature as `BaseFeaturizer`. \n",
    "    In the training class, this will be used like this:\n",
    "    \n",
    "    featurize = BaseFeaturizer()\n",
    "    features = featurize(t, sent, prev_tag)\n",
    "    \n",
    "    see below for the meaning of parameters\n",
    "    \"\"\"\n",
    "    def __call__(self, t, sent, prev_tag, **kwargs):\n",
    "        \"\"\"\n",
    "        input:\n",
    "            t: int, the current index of the word in the sentence\n",
    "            sent: list[string], the entire current sentence\n",
    "            prev_tag: string, previous word's tag. If t=0, prev_tag would be `START`\n",
    "                (remember in First order MEMM, the entire sentence both before and after the current\n",
    "                word, together with the previous 1 tage can be used to construct features. )\n",
    "            kwargs: Use this as needed to pass extra parameters\n",
    "        \"\"\"\n",
    "        features = dict()\n",
    "        features['PREV_TAG_%s' % prev_tag] = 1\n",
    "        features['UNIGRAM_%s' % sent[t]] = 1\n",
    "\n",
    "        return features\n",
    "\n",
    "    \n",
    "class FOMEMM:\n",
    "    \"\"\"\n",
    "    First order maximum entropy Markov model\n",
    "    \"\"\"\n",
    "    def __init__(self, Featurizer=BaseFeaturizer, path_search=viterbi_path_search, \n",
    "                 tag_vocab=tags, **kwargs):\n",
    "        \"\"\"\n",
    "        input: \n",
    "            Featurizer: BaseFeaturizer class\n",
    "            path_search: function for path search\n",
    "            tag_vocab: tag dictionary, you will less likely need to change this\n",
    "            \n",
    "            kwargs: Use as needed to pass extra parameters\n",
    "        \"\"\"\n",
    "        self.feature_vocab = {}\n",
    "        self.featurize = Featurizer()\n",
    "        self.path_search = path_search\n",
    "        self.tag_vocab = tag_vocab\n",
    "        self.reverse_tag_vocab = {v:k for k, v in tag_vocab.items()}\n",
    "        self.model = None\n",
    "\n",
    "        \"\"\"\n",
    "        Feel free to add code here as you need\n",
    "        \"\"\"\n",
    "\n",
    "    def featurize(self, X):\n",
    "        \"\"\"\n",
    "        # Featurize input text\n",
    "\n",
    "        :param X: list of texts\n",
    "        :return: list of featurized vectors\n",
    "        \"\"\"\n",
    "        featurized_data = []\n",
    "        for text in X:\n",
    "            feats = self.feature_method(text)\n",
    "            featurized_data.append(feats)\n",
    "        return featurized_data\n",
    "\n",
    "    def collect_features(self, X, y):\n",
    "        \"\"\"\n",
    "        Create feature vocabulary from all input data\n",
    "        input:\n",
    "            X: list of sentences\n",
    "            y: list of list of tags\n",
    "        \"\"\"\n",
    "        feature_counts = defaultdict(int)\n",
    "        for sent, labs in zip(X, y):\n",
    "            for t in range(len(labs)):\n",
    "                if t == 0: prev_tag = \"START\"\n",
    "                feats = self.featurize(t, sent, prev_tag)\n",
    "                \n",
    "                for f in feats:\n",
    "                    feature_counts[f] += 1\n",
    "                    \n",
    "        \"\"\"\n",
    "        Below I just use all the features I collect to construct\n",
    "        the feature_vocab. Feel free to add code here as needed.\n",
    "        \"\"\"\n",
    "        \n",
    "        feature_vocab = {k:i+1 for i, k in enumerate(feature_counts.keys())}\n",
    "        feature_vocab['_UNKNOWN_'] = 0\n",
    "        \n",
    "        return feature_vocab\n",
    "                \n",
    "    def pipeline(self, X, y):\n",
    "        \"\"\"\n",
    "        Translate all input raw data into trainable numerical data\n",
    "        input:\n",
    "            X: list of sentences\n",
    "            y: list of list of tags\n",
    "        \"\"\"\n",
    "        ntot = sum([len(sent) for sent in X])\n",
    "        X_new = sparse.dok_matrix((ntot, len(self.feature_vocab)))\n",
    "        \n",
    "        i = 0\n",
    "        for sent, labs in zip(X, y):\n",
    "            for t in range(len(labs)):\n",
    "                if t == 0: prev_tag = \"START\"\n",
    "                feats = self.featurize(t, sent, prev_tag)\n",
    "                \n",
    "                for f, v in feats.items():\n",
    "                    X_new[i, self.feature_vocab[f]] = v\n",
    "                    \n",
    "                i += 1\n",
    "                  \n",
    "        y_new = np.array([self.tag_vocab[t] for labs in y for t in labs])\n",
    "        \n",
    "        return X_new, y_new\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        input:\n",
    "            X: list of sentences\n",
    "            y: list of list of tags\n",
    "        \"\"\"\n",
    "        self.feature_vocab = self.collect_features(X, y)\n",
    "        self.X, self.y = self.pipeline(X, y)\n",
    "        \n",
    "        self.model = LogisticRegression(C=1.0, multi_class='auto')\n",
    "        self.model.fit(self.X, self.y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        results = []\n",
    "        L = len(self.tag_vocab) - 1\n",
    "        for j, sent in enumerate(X):\n",
    "            T = len(sent)\n",
    "            Y_pred = np.zeros((T, L+1, L))\n",
    "            for t in range(len(sent)):\n",
    "                # We need to make one prediction for each possible prev_tag\n",
    "                for prev_tag, i in self.tag_vocab.items():\n",
    "                    feats = self.featurize(t, sent, prev_tag)\n",
    "                    X0 = sparse.lil_matrix((1, len(self.feature_vocab)))\n",
    "                    for f, v in feats.items():\n",
    "                        X0[0, self.feature_vocab.get(f, 0)] = v\n",
    "                        \n",
    "                    prob = self.model.predict_proba(X0)\n",
    "                    Y_pred[t, i, :] = prob\n",
    "            \n",
    "            tag_path = self.path_search(Y_pred)\n",
    "            results.append([self.reverse_tag_vocab[t] for t in tag_path])\n",
    "            \n",
    "            print(\"Generation predictions, %.3f%% complete.\" % (j*100/len(X)), end=\"\\r\")\n",
    "            \n",
    "        return results\n",
    "\n",
    "    def score(self, X, y):\n",
    "        tot_tokens = sum([len(sent) for sent in X])\n",
    "        tot_sents = len(X)\n",
    "        \n",
    "        y_pred = self.predict(X)\n",
    "        \n",
    "        right_tokens, right_sents = 0, 0\n",
    "        \n",
    "        for labs0, labs1 in zip(y, y_pred):\n",
    "            right_sents += (labs0 == labs1)\n",
    "            for lab0, lab1 in zip(labs0, labs1):\n",
    "                right_tokens += (lab0 == lab1)\n",
    "                \n",
    "        return {\"tokens\" : 1.0 * right_tokens / tot_tokens, \n",
    "                \"sentences\": 1.0 * right_sents / tot_sents}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check how the model works with the base featurizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T05:20:50.935744Z",
     "start_time": "2019-04-03T05:17:46.029658Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fomemm = FOMEMM().fit(train, train_label)\n",
    "# fomemm.score(dev[:10], dev_label[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement your own featurizer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T04:39:10.058296Z",
     "start_time": "2019-04-03T04:39:10.026168Z"
    }
   },
   "outputs": [],
   "source": [
    "class BetterFeaturizer(BaseFeaturizer):\n",
    "    \"\"\"\n",
    "    A template for the Featurizer. Later you will have to create your own featurizer, it has to follow\n",
    "    the class signature as `BaseFeaturizer`. \n",
    "    In the training class, this will be used like this:\n",
    "    \n",
    "    featurize = BaseFeaturizer()\n",
    "    features = featurize(t, sent, prev_tag)\n",
    "    \n",
    "    see below for the meaning of parameters\n",
    "    \"\"\"\n",
    "    def __call__(self, t, sent, prev_tag, **kwargs):\n",
    "        \"\"\"\n",
    "        input:\n",
    "            t: int, the current index of the word in the sentence\n",
    "            sent: list[string], the entire current sentence\n",
    "            prev_tag: string, previous word's tag. If t=0, prev_tag would be `START`\n",
    "                (remember in First order MEMM, the entire sentence both before and after the current\n",
    "                word, together with the previous 1 tage can be used to construct features. )\n",
    "            kwargs: Use this as needed to pass extra parameters\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        Implement your code here\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fomemm = FOMEMM(Featurizer=BetterFeaturizer).fit(train, train_label)\n",
    "fomemm.score(dev, dev_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T05:15:01.277528Z",
     "start_time": "2019-04-03T05:14:59.503776Z"
    }
   },
   "outputs": [],
   "source": [
    "prediction = fomemm.predict(test[:10])\n",
    "save_prediction(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
